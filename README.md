Projeto MLOps: Previs√£o de A√ß√µes EMBR3 com LSTM - Avalia√ß√£o substituta FIAP

Resumo: Este projeto demonstra a implementa√ß√£o de um pipeline Machine Learning (MLOps) para a previs√£o de s√©ries temporais. O foco √© prever o pre√ßo de abertura das a√ß√µes da Embraer (EMBR3) usando uma Rede Neural Recorrente (RNN) do tipo LSTM.


Empresa (Ticker):	Embraer (EMBR3)
Algoritmo:	LSTM (Long Short-Term Memory)
Previs√£o:	Pre√ßo de Abertura da a√ß√£o no dia seguinte.
Janela de Observa√ß√£o:	Os √∫ltimos 90 dias de pre√ßos de fechamento.

Componentes Chave:
 Modelo Treinado (Artefato):
 Algoritmo: LSTM, ideal para capturar depend√™ncias de longo prazo em s√©ries temporais.

Serializa√ß√£o: O modelo e o MinMaxScaler foram serializados (salvos em .h5 e ajustado via CSV, respectivamente) para serem carregados diretamente na API.
Servi√ßo de Predi√ß√£o (API):
Framework: Flask (Python).

Endpoint: Recebe uma requisi√ß√£o POST no /predict contendo exatamente 90 pre√ßos de entrada.
 Virtualiza√ß√£o (Container):
 Ferramenta: Docker.
 Servidor: Gunicorn, usado para garantir a estabilidade e o desempenho em ambiente de produ√ß√£o.

Como Executar e Testar:
1. Pr√©-requisitos
- Python 3.x
- Docker
- pip install -r requirements.txt (Instala Flask, TensorFlow, Scikit-learn, etc.)

2. Teste Local da API
Iniciar o Servidor Flask: (O servidor deve iniciar na porta 5000, dependendo da sua configura√ß√£o local.)

Fazer a Requisi√ß√£o (Postman/cURL):
Envie um POST para o endpoint http://localhost:5000/predict (ajuste a porta se necess√°rio) com um corpo JSON contendo exatamente 90 pre√ßos de fechamento:
{
    "data": [
        59.97,
        59.12,
        ... (87 valores restantes) ...
        57.18 
    ]
}

√â um √≥timo projeto de Machine Learning Engineering! Seu trabalho de construir uma API com Flask, Docker e Cloud Run, usando LSTM para prever a√ß√µes da Embraer, cobre perfeitamente os requisitos do desafio.

Com base nas informa√ß√µes do seu projeto e nos requisitos do desafio, preparei uma sugest√£o de estrutura para o seu arquivo README.md do GitHub. O objetivo √© ser claro, direto e focado em MLOps, como exige o desafio.

üöÄ Projeto MLOps: Previs√£o de A√ß√µes EMBR3 com LSTM
Este projeto demonstra a implementa√ß√£o completa de um pipeline de Machine Learning (MLOps) para a previs√£o de s√©ries temporais. O foco √© prever o pre√ßo de abertura das a√ß√µes da Embraer (EMBR3) usando uma Rede Neural Recorrente (RNN) do tipo LSTM.

üéØ Objetivo do Projeto
O objetivo principal deste sistema √© fornecer uma previs√£o robusta e acess√≠vel sobre a cota√ß√£o das a√ß√µes da Embraer, seguindo todos os requisitos de um desafio de MLOps.

Detalhes da Previs√£o
Par√¢metro	Detalhe
Empresa (Ticker)	Embraer (EMBR3)
Algoritmo	LSTM (Long Short-Term Memory)
Previs√£o	Pre√ßo de Abertura da a√ß√£o no dia seguinte.
Janela de Observa√ß√£o	Os √∫ltimos 90 dias de pre√ßos de fechamento.
Compara√ß√£o	Acur√°cia testada em janeiro de 2025.

Exportar para as Planilhas
‚öôÔ∏è Arquitetura do MLOps e Deploy
A estrat√©gia de MLOps foi empregada para garantir a reprodutibilidade, escalabilidade e monitoramento do modelo em produ√ß√£o.


Componentes Chave:
Modelo Treinado (Artefato):


Algoritmo: LSTM, ideal para capturar depend√™ncias de longo prazo em s√©ries temporais.


Serializa√ß√£o: O modelo e o MinMaxScaler foram serializados (salvos em .h5 e ajustado via CSV, respectivamente) para serem carregados diretamente na API.

Servi√ßo de Predi√ß√£o (API):


Framework: Flask (Python).

Endpoint: Recebe uma requisi√ß√£o POST no /predict contendo exatamente 90 pre√ßos de entrada.

Virtualiza√ß√£o (Container):


Ferramenta: Docker.

Servidor: Gunicorn, usado para garantir a estabilidade e o desempenho em ambiente de produ√ß√£o.

Deploy e Hospedagem:

Plataforma: Google Cloud Run. Servi√ßo Serverless que gerencia automaticamente a escalabilidade e o ambiente.

URL da API: [INSIRA O LINK DO SEU CLOUD RUN AQUI]

Monitoramento:


Ferramentas: Google Cloud Logging e Cloud Monitoring.

Fun√ß√£o: Acompanha logs de requisi√ß√£o, lat√™ncia e erros (c√≥digo 400 se o input n√£o for de 90 dias, por exemplo).

üíª Como Executar e Testar
1. Pr√©-requisitos
Python 3.x

Docker

pip install -r requirements.txt (Instala Flask, TensorFlow, Scikit-learn, etc.)

2. Teste Local da API
Iniciar o Servidor Flask:

Bash

python API.py
(O servidor deve iniciar na porta 5000 ou 8080, dependendo da sua configura√ß√£o local.)

Fazer a Requisi√ß√£o (Postman/cURL):
Envie um POST para o endpoint http://localhost:5000/predict (ajuste a porta se necess√°rio) com um corpo JSON contendo exatamente 90 pre√ßos de fechamento:

JSON

{
    "data": [
        59.97,
        59.12,
        ... (87 valores restantes) ...
        57.18 
    ]
}
3. Build e Execu√ß√£o Docker
Construa a imagem e execute o cont√™iner:
